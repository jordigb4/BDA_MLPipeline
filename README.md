# Large Scale Data Engineering Project for AI

## Description

A containerized data pipeline using Apache Airflow, PostgreSQL, Hadoop HDFS, and a Streamlit frontend for data visualization. Designed for orchestrating ETL workflows and managing data in a distributed environment.


## Project Files and Directory Overview

### airflow/
Contains the configuration and custom code for the Airflow service.

#### dags/
Contains the Airflow DAGs that define the data pipelines for collecting, processing, and storing urban data.

##### __pycache__
Automatically generated by Python to cache compiled versions of imported modules.



##### landing/
Contains ingestion DAG tasks responsible for collecting raw data from APIs and storing it in HDFS.

###### __pycache__
A system-generated folder that stores compiled Python bytecode.

###### __init__.py
Marks the folder as a Python module, enabling imports.

###### air_quality_DL.py
Defines the Airflow tasks responsible for downloading air quality data from OpenAQ and storing it in HDFS.

###### electricity_DL.py
Contains Airflow tasks for retrieving electricity usage data from the EIA API and saving it to HDFS.

###### traffic_acc_DL.py
Implements the DAG tasks to collect traffic accident data from the LA City Open Data portal and load it into HDFS.

###### weather_DL.py
Defines tasks for fetching historical weather data from NOAA S3 storage and writing it to HDFS.

###### class_types.py
Provides enumerations to standardize and group the station identifiers used across datasets.



##### formatting/
Includes tasks that clean and standardize raw data (e.g., converting formats, handling missing values).

###### __pycache__
A system-generated folder that stores compiled Python bytecode.

###### __init__.py
Marks the folder as a Python module, enabling imports.

###### air_quality_FR.py
Defines Airflow tasks for formatting raw air quality data into a standardized structure.

###### electricity_FR.py
Contains tasks for formatting electricity data into the required format after it’s ingested.

###### traffic_acc_FR.py
Implements tasks to format traffic accident data into the proper format after it’s collected.

###### weather_FR.py
Defines tasks for formatting weather data, applying any necessary transformations.

###### class_types.py
Provides shared enumerations for standardizing the different types of data.




##### quality/
Implements data quality checks to validate the correctness and consistency of the formatted data.

###### __pycache__
A system-generated folder that stores compiled Python bytecode.

###### __init__.py
Marks the folder as a Python module, enabling imports.

###### air_quality_QL.py
This script focuses on evaluating and analyzing air quality metrics and constraints, ensuring that the air quality data meets certain standards or thresholds.

###### electricity_QL.py
This script examines the quality metrics and constraints associated with electricity data, ensuring it complies with specific requirements.

###### traffic_acc_QL.py
This file analyzes traffic accident data, assessing its quality and checking whether it meets relevant metrics and constraints for accurate analysis.

###### weather_QL.py
This script evaluates the quality of weather-related data, ensuring that the information meets predefined quality metrics and constraints for reliability and accuracy.

###### quality_utils.py
This utility script contains functions for profiling data and functions for calculating quality metrics.




##### exploitation/
Performs feature engineering and combines datasets for modeling.

###### __pycache__
A system-generated folder that stores compiled Python bytecode.

###### __init__.py
Marks the folder as a Python module, enabling imports.

###### air_electricity_weather.sql

This SQL script performs the operation of combining or joining air quality, electricity, and weather data from different sources into a unified dataset for modeling purposes.

###### trafficAcc_weather.sql
This SQL file combines traffic accident data and weather data into one dataset, preparing it for further analysis or modeling.

###### weather_electricity.sql
This SQL script merges weather data and electricity data into a single dataset, which is then used for modeling purposes.



##### data_analysis/
Runs data analysis tasks on the processed datasets.

###### __pycache__
A system-generated folder that stores compiled Python bytecode.

###### utils/
Subfolder containing scripts for running specific data analysis experiments on the processed datasets.

####### __init.py__
Marks the utils directory as a Python package, allowing imports between modules.

####### exp1_DA.py
Runs the first data analysis experiment.

####### exp2_DA.py
Executes the second data analysis experiment.

####### exp3_DA.py
Performs the third data analysis experiment.



##### utils/
Utility functions and orchestrator DAG scripts, including the main pipeline definition.

###### __init__.py
Acting as a marker to make the folder importable.

###### mlpipeline.py
This file defines the full Machine Learning Pipeline DAG using Airflow.



#### __init__.py
Initializes the Airflow Python package environment.

#### .env
Stores all environment variables, including API endpoints, credentials, HDFS and PostgreSQL configs used by the data pipelines.

#### Dockerfile
Defines the custom Airflow Docker image, installing required Python packages, AWS CLI, and Java for running Spark or HDFS tools.

#### requirements.txt
Lists all Python dependencies needed by the Airflow DAGs and scripts, including libraries for data processing, ML, and cloud integration.

### streamlit-app/
Contains the Streamlit application that allows users to interact with the results od the data analysis.

#### app.py
Main Streamlit script that defines the interactive dashboard for exploring weather, air quality, energy, and traffic data in Los Angeles.

#### Dockerfile
Defines the Docker image to run the Streamlit app, including dependencies and configuration for containerized deployment.

#### requirements.txt
Lists all Python dependencies required to run the dashboard application.
#### utils.py
Contains helper functions to load pickled Plotly figures from HDFS for visualization in the dashboard.

### docker-compose.yaml
Main file that defines and configures all services in the project: PostgreSQL, HDFS, Airflow and Streamlit App

### postgresql-42.7.3.jar

PostgreSQL JDBC driver required for Airflow to connect to the PostgreSQL database.

## Authors

-Alberto Jerez
-Jordi Granja
-Marta Carrión


